import degirum as dg
import degirum_tools
import degirum_tools.streams as dgstreams
from picamera2 import Picamera2
import cv2
import time
import requests
import sys
import os
from datetime import datetime
from gpiozero import MotionSensor, OutputDevice
import threading

# inference_host_address = "@cloud"
inference_host_address = "@local"

# choose zoo_url
#zoo_url = "degirum/models_hailort"
zoo_url = "../models"

# set token
#token = degirum_tools.get_token()
token = '' # leave empty for local inference

# ì´ë¯¸ì§€ ì „ì†¡ ì„œë²„ ì£¼ì†Œ
SERVER_LINK = "https://davmo.xyz/api/uploads"

# ì´ë¯¸ì§€ ì €ì¥ í´ë”
SAVE_DIR = "captures"

#PIR ì„¼ì„œ í•€
PIR_PIN = 17
pir = MotionSensor(PIR_PIN)

#ë¦´ë ˆì´ ëª¨ë“ˆ í•€
RELAY_PIN = 27
relay = OutputDevice(RELAY_PIN, active_high=True, initial_value=False)

# RFID ì„¤ì •
SERIAL_PORT = '/dev/ttyS0'

#PIR ëŒ€ê¸°ì‹œê°„ í•´ì œí›„ ì‘ë™ì‹œê°„
CAMERA_ACTION_TIME = 20.0

# ì €ì¥ í´ë” ì—†ìœ¼ë©´ ìƒì„±í•˜ë„ë¡
if not os.path.exists(SAVE_DIR):
    os.makedirs(SAVE_DIR)

def picamera_generator(index):
    # picam2 = Picamera2(index)
    # config = picam2.create_preview_configuration(main={"size": (640, 480)}) 
    # picam2.configure(config)
    # picam2.start()
    # time.sleep(1.0)
    print(f'-- 2. {index}ë²ˆ ì¹´ë©”ë¼ PIR ì¸ì‹ ëŒ€ê¸°ì¤‘. ê°ì§€ë˜ë©´ ì¹´ë©”ë¼ ì‹œì‘--')
    picam2 = None
    active_until = 0
    is_running = False

    try:
        while True:
            current_time = time.time()
        
            if pir.value:
                if not is_running:
                    print("-- 3. PIR ì›€ì§ì„ ê°ì§€. ì¹´ë©”ë¼ ë¶€íŒ… --")
                active_until = current_time + CAMERA_ACTION_TIME
            
            if current_time < active_until:
                #ì‹œê°„ì´ ë‚¨ì•˜ëŠ”ë° ì¼œì§€ì§€ ì•Šì•˜ì„ ë•Œ
                if not is_running:
                    picam2 = Picamera2(index)
                    config = picam2.create_preview_configuration(main={"size": (640, 480)})
                    picam2.configure(config)
                    picam2.start()

                    print("-- 4. ê³ ë¶€ ì¡°ëª… ë™ì‘--")
                    relay.on()
                    is_running = True

                frame_rgb = picam2.capture_array()
                frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)
                yield frame_bgr

            else:
                #ì‹œê°„ì¢…ë£Œ ì´í›„ì—ë„ ì•„ì§ ë™ì‘ì¤‘ì¸ ê²½ìš°
                if is_running:
                    print(f"\n -- 5. {CAMERA_ACTION_TIME}ì´ˆ ê²½ê³¼, {index}ë²ˆ ì¹´ë©”ë¼ ëŒ€ê¸°ëª¨ë“œ ì „í™˜ --")
                    if picam2:
                        picam2.stop()
                        picam2.close()
                        picam2 = None
                    
                    print("-- 6. ê³ ë¶€ì¡°ëª… êº¼ì§ --")
                    relay.off()
                    is_running=False

                time.sleep(0.1)
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ : {e}")
    finally:
        if picam2:
            picam2.stop()
            picam2.close()
            relay.off()


class NotificationGizmo(dgstreams.Gizmo):
    def __init__(self, camera_name):
        super().__init__([(10,)])
        self.camera_name = camera_name
        self.frame_count = 0
        self.last_save_time = 0

    def run(self):
        #print(f"[{self.camera_name}]")
        
        for result_wrapper in self.get_input(0):
            if self._abort:
                break
            
            inf_result = None

            #ì˜ˆì™¸ì²˜ë¦¬ë¥¼ ìœ„í•´ ì†ì„± ë¨¼ì € ê²€ìƒ‰.
            if hasattr(result_wrapper.data, 'result'):
                inf_result = result_wrapper.data
            else:
                try:
                    for item in result_wrapper.meta._meta_list:
                        if hasattr(item, 'results'):
                            inf_result = item
                            break
                except: pass

            if inf_result and inf_result.results:
                for obj in inf_result.results:
                    label = obj.get('label', '')
                    score = obj.get('score', 0) * 100

                    if 'scooter' in label and score >= 80.0:
                        print(f"\n[{self.camera_name}] found. type:'{label}' ({score:.1f}%)", flush=True)

                        if time.time() - self.last_save_time > 2.0:
                            t = threading.Thread(target=self.save_and_send, args=(result_wrapper.data.copy(), label, score))
                            t.start()
                            self.last_save_time = time.time()

            #ì‹œê°„ ì§€ë‚ ë•Œë§ˆë‹¤ í”„ë ˆì„ ì¹´ìš´íŠ¸í•´ì„œ ì  ì°ìŒ(ì§„í–‰ìƒí™© íŒŒì•….)
            self.frame_count += 1
            if self.frame_count % 180 == 0:
                print(".", end="", flush=True)
            
            self.send_result(result_wrapper)

    #ì´ë¯¸ì§€ë¥¼ ì €ì¥í•˜ê³  ì„œë²„ë¡œ ì „ì†¡í•˜ëŠ” í•¨ìˆ˜
    def save_and_send(self, image_array, label, score):
            try:
                # 1. íŒŒì¼ëª… ìƒì„± (ì˜ˆ: captures/cam0_scooter_20231025_123001.jpg)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"{self.camera_name}_{label.replace(' ', '_')}_{timestamp}.jpg"
                filepath = os.path.join(SAVE_DIR, filename)

                # 2. ë¡œì»¬ ì €ì¥ (OpenCV ì‚¬ìš©)
                cv2.imwrite(filepath, image_array)
                print(f"   ğŸ’¾ ì €ì¥ ì™„ë£Œ: {filepath}")

                # 3. ì„œë²„ ì „ì†¡ (Requests ì‚¬ìš©)
                # ì´ë¯¸ì§€ë¥¼ ë©”ëª¨ë¦¬ìƒì—ì„œ jpgë¡œ ì¸ì½”ë”© (íŒŒì¼ ë‹¤ì‹œ ì½ëŠ” ê²ƒë³´ë‹¤ ë¹ ë¦„)
                _, img_encoded = cv2.imencode('.jpg', image_array)
                files = {
                    'imageFile': (filename, img_encoded.tobytes(), 'image/jpeg')
                }
                data = {
                    'camera': self.camera_name,
                    'label': label,
                    'score': f"{score:.1f}"
                }
                
                # íƒ€ì„ì•„ì›ƒ 1ì´ˆ ì„¤ì • (ì„œë²„ê°€ ì‘ë‹µ ì—†ì–´ë„ 1ì´ˆ ë’¤ì— ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰)
                response = requests.post(SERVER_LINK, files=files, data=data, timeout=10.0)
                
                if response.status_code == 200:
                    print(f"   ğŸ“¡ ì„œë²„ ì „ì†¡ ì„±ê³µ! (200 OK)")
                else:
                    print(f"   âš ï¸ ì„œë²„ ì „ì†¡ ì‹¤íŒ¨ (Code: {response.status_code})")

            except Exception as e:
                # ì—ëŸ¬ê°€ ë‚˜ë„ í”„ë¡œê·¸ë¨ì´ ë©ˆì¶”ì§€ ì•Šë„ë¡ ì˜ˆì™¸ ì²˜ë¦¬
                print(f"   âŒ ì €ì¥/ì „ì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# Define the configurations for video file and webcam
configurations = [
    {
        "model_name": "scooter_model",
        "source" : '0',
        "display_name": "cam0",
    },
    {
        "model_name": "scooter_model",
        "source" : '1',
        "display_name": "cam1",
    },
]


# load models
models = [
    dg.load_model(cfg["model_name"], inference_host_address, zoo_url, token)
    for cfg in configurations
]

# define gizmos
sources = [dgstreams.IteratorSourceGizmo(picamera_generator(int(cfg["source"]))) for cfg in configurations]
detectors = [dgstreams.AiSimpleGizmo(model) for model in models]
notifiers = [NotificationGizmo(cfg["display_name"]) for cfg in configurations]
display = dgstreams.VideoDisplayGizmo(
    [cfg["display_name"] for cfg in configurations], show_ai_overlay=True, show_fps=True
)

# create pipeline
pipeline = (
    (source >> detector for source, detector in zip(sources, detectors)),
    (detector >> notifiers >> display[di] for di, (detector, notifiers) in enumerate(zip(detectors, notifiers))),
)

# start composition
print("1. ì‹œìŠ¤í…œ ì‹œì‘")
dgstreams.Composition(*pipeline).start()